{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#From-Scratch\" data-toc-modified-id=\"From-Scratch-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>From Scratch</a></span></li><li><span><a href=\"#sklearn\" data-toc-modified-id=\"sklearn-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>sklearn</a></span></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>TF-IDF</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sources I referenced while working:\n",
    "\n",
    "* [How to extract keywords from text with TF-IDF and Python’s Scikit-Learn](https://www.freecodecamp.org/news/how-to-extract-keywords-from-text-with-tf-idf-and-pythons-scikit-learn-b2a0f3d7e667/)\n",
    "* [TFIDF/TFIDF.ipynb at master · mayank408/TFIDF · GitHub](https://github.com/mayank408/TFIDF/blob/master/TFIDF.ipynb)\n",
    "* [How to process textual data using TF-IDF in Python](https://www.freecodecamp.org/news/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, itertools, pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Nah I ain't scared to go over there\", \" I don't think it's none to be scared of\", \" But, but it's still strange to hear\", \" I think them old people say that spirit will not let you dig to get to the gold, whatever's down there\", \" That's what them old people used to say\", \" It's not going let ya\", \" And it's kinda strange they clean all that\", ' They clean all the distance, but they never clean that spot there', '']\n"
     ]
    }
   ],
   "source": [
    "# Our string:\n",
    "text = open('texts/legend.txt', 'r').read()\n",
    "\n",
    "# String into list of words:\n",
    "sentences = text.split(\".\")\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last item in the list above is empty. To get rid of it:\n",
    "\n",
    "    del sentences[-1]\n",
    "\n",
    "I then rechecked the length of the list, `len(sentences)` and saw that it had dropped from `9` to `8`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del sentences[-1]\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bows = []\n",
    "for sentence in sentences:\n",
    "    words = re.sub(\"[^a-zA-Z']\",\" \", sentence).lower().split()\n",
    "    bows.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: ['nah', 'i', \"ain't\", 'scared', 'to', 'go', 'over', 'there']\n",
      "9: ['i', \"don't\", 'think', \"it's\", 'none', 'to', 'be', 'scared', 'of']\n",
      "7: ['but', 'but', \"it's\", 'still', 'strange', 'to', 'hear']\n",
      "21: ['i', 'think', 'them', 'old', 'people', 'say', 'that', 'spirit', 'will', 'not', 'let', 'you', 'dig', 'to', 'get', 'to', 'the', 'gold', \"whatever's\", 'down', 'there']\n",
      "8: [\"that's\", 'what', 'them', 'old', 'people', 'used', 'to', 'say']\n",
      "5: [\"it's\", 'not', 'going', 'let', 'ya']\n",
      "8: ['and', \"it's\", 'kinda', 'strange', 'they', 'clean', 'all', 'that']\n",
      "12: ['they', 'clean', 'all', 'the', 'distance', 'but', 'they', 'never', 'clean', 'that', 'spot', 'there']\n"
     ]
    }
   ],
   "source": [
    "for item in bows:\n",
    "    print(str(len(item)) + \": \" + str(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nah': 1, 'i': 3, \"ain't\": 1, 'scared': 2, 'to': 6, 'go': 1, 'over': 1, 'there': 3, \"don't\": 1, 'think': 2, \"it's\": 4, 'none': 1, 'be': 1, 'of': 1, 'but': 3, 'still': 1, 'strange': 2, 'hear': 1, 'them': 2, 'old': 2, 'people': 2, 'say': 2, 'that': 3, 'spirit': 1, 'will': 1, 'not': 2, 'let': 2, 'you': 1, 'dig': 1, 'get': 1, 'the': 2, 'gold': 1, \"whatever's\": 1, 'down': 1, \"that's\": 1, 'what': 1, 'used': 1, 'going': 1, 'ya': 1, 'and': 1, 'kinda': 1, 'they': 3, 'clean': 3, 'all': 2, 'distance': 1, 'never': 1, 'spot': 1}\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "for item in bows:\n",
    "    for word in item:\n",
    "        try:\n",
    "            counts[word] += 1\n",
    "        except: \n",
    "            counts[word] = 1\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termfreq(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 45)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# fit the model to the data \n",
    "vecs = vectorizer.fit(sentences)\n",
    "\n",
    "# transform the data according to the fitted model\n",
    "bow = vecs.transform(sentences)\n",
    "\n",
    "# see how many features we have\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ain', 'all', 'and', 'be', 'but', 'clean', 'dig', 'distance', 'don', 'down']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_array = bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ain</th>\n",
       "      <th>all</th>\n",
       "      <th>and</th>\n",
       "      <th>be</th>\n",
       "      <th>but</th>\n",
       "      <th>clean</th>\n",
       "      <th>dig</th>\n",
       "      <th>distance</th>\n",
       "      <th>don</th>\n",
       "      <th>down</th>\n",
       "      <th>...</th>\n",
       "      <th>there</th>\n",
       "      <th>they</th>\n",
       "      <th>think</th>\n",
       "      <th>to</th>\n",
       "      <th>used</th>\n",
       "      <th>what</th>\n",
       "      <th>whatever</th>\n",
       "      <th>will</th>\n",
       "      <th>ya</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ain  all  and  be  but  clean  dig  distance  don  down  ...  there  they  \\\n",
       "0    1    0    0   0    0      0    0         0    0     0  ...      1     0   \n",
       "1    0    0    0   1    0      0    0         0    1     0  ...      0     0   \n",
       "2    0    0    0   0    2      0    0         0    0     0  ...      0     0   \n",
       "3    0    0    0   0    0      0    1         0    0     1  ...      1     0   \n",
       "4    0    0    0   0    0      0    0         0    0     0  ...      0     0   \n",
       "5    0    0    0   0    0      0    0         0    0     0  ...      0     0   \n",
       "6    0    1    1   0    0      1    0         0    0     0  ...      0     1   \n",
       "7    0    1    0   0    1      2    0         1    0     0  ...      1     2   \n",
       "\n",
       "   think  to  used  what  whatever  will  ya  you  \n",
       "0      0   1     0     0         0     0   0    0  \n",
       "1      1   1     0     0         0     0   0    0  \n",
       "2      0   1     0     0         0     0   0    0  \n",
       "3      1   2     0     0         1     1   0    1  \n",
       "4      0   1     1     1         0     0   0    0  \n",
       "5      0   0     0     0         0     0   1    0  \n",
       "6      0   0     0     0         0     0   0    0  \n",
       "7      0   0     0     0         0     0   0    0  \n",
       "\n",
       "[8 rows x 45 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordframe = pd.DataFrame(data= tf_array, columns = tf_feature_names)\n",
    "wordframe.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordframe.to_csv('outputs/words.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 18)\t0.42484368112477977\n",
      "  (0, 0)\t0.42484368112477977\n",
      "  (0, 27)\t0.35605216161420306\n",
      "  (0, 38)\t0.2384522822616481\n",
      "  (0, 11)\t0.42484368112477977\n",
      "  (0, 24)\t0.42484368112477977\n",
      "  (0, 35)\t0.3072438017722249\n",
      "  (1, 27)\t0.33872226489301194\n",
      "  (1, 38)\t0.22684624845527496\n",
      "  (1, 8)\t0.40416553923915166\n",
      "  (1, 37)\t0.33872226489301194\n",
      "  (1, 15)\t0.25627348996602684\n",
      "  (1, 20)\t0.40416553923915166\n",
      "  (1, 3)\t0.40416553923915166\n",
      "  (1, 22)\t0.40416553923915166\n",
      "  (2, 38)\t0.2248871593770373\n",
      "  (2, 15)\t0.254060261408565\n",
      "  (2, 4)\t0.671593984809181\n",
      "  (2, 30)\t0.40067508568695387\n",
      "  (2, 31)\t0.3357969924045905\n",
      "  (2, 14)\t0.40067508568695387\n",
      "  (3, 38)\t0.2823687076105529\n",
      "  (3, 35)\t0.18191487706664233\n",
      "  (3, 37)\t0.21081364322323456\n",
      "  (3, 34)\t0.21081364322323456\n",
      "  :\t:\n",
      "  (4, 40)\t0.4253747324300509\n",
      "  (4, 39)\t0.4253747324300509\n",
      "  (5, 15)\t0.3249854609640874\n",
      "  (5, 21)\t0.4295403766095668\n",
      "  (5, 17)\t0.4295403766095668\n",
      "  (5, 12)\t0.5125302819766763\n",
      "  (5, 43)\t0.5125302819766763\n",
      "  (6, 15)\t0.2676227777546686\n",
      "  (6, 31)\t0.3537228662630598\n",
      "  (6, 32)\t0.2676227777546686\n",
      "  (6, 2)\t0.4220643512453595\n",
      "  (6, 16)\t0.4220643512453595\n",
      "  (6, 36)\t0.3537228662630598\n",
      "  (6, 5)\t0.3537228662630598\n",
      "  (6, 1)\t0.3537228662630598\n",
      "  (7, 35)\t0.2118697004898768\n",
      "  (7, 4)\t0.24552705182283666\n",
      "  (7, 32)\t0.1857630305807689\n",
      "  (7, 33)\t0.24552705182283666\n",
      "  (7, 36)\t0.4910541036456733\n",
      "  (7, 5)\t0.4910541036456733\n",
      "  (7, 1)\t0.24552705182283666\n",
      "  (7, 7)\t0.2929644241990399\n",
      "  (7, 19)\t0.2929644241990399\n",
      "  (7, 29)\t0.2929644241990399\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
