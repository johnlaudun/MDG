{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In case you are wondering what this little bit of \"magic\" does: it essentially tells Jupyter notebooks to embed whatever graphic is created by `matplotlib` into the current page. The second line makes that graphic a higher resolution and 2:1 in aspect, which fits better on a page, to my mind, than other aspects, but you can adjust that as you like. I place this at the top of a page so I do it first thing and then get on with the work I want to do. If I am creating nothing graphical, then it's not necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "figsize(12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Exploring a Text with the NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Table of Contents <a name=\"toc\"></a>\n",
    "\n",
    "**[Loading a File & Understanding What It Is](#file)**  \n",
    "**[Tokenizing](#tokenizing)**  \n",
    "[A Quick Note about Normalization](#norm)  \n",
    "[Using regex to Tokenize](#REtoke)   \n",
    "[Using NLTK Tokenizers](#nltktoken)  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the first two notebooks we learned how to load a file, create a word list out of a text string, and then to count words and visualize those counts. In this notebook we will use the `NLTK` to explore how various words occur or are used within a text. Once you have seen how these commands work, feel free to restart the notebook and upload your own text. In the next notebook, we will look at how to load more than one text. \n",
    "\n",
    "The first thing we are going to do is load the libraries we know we are going to use, load our text file, and create our word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "mdg = open('texts/mdg.txt', 'r').read()\n",
    "mdg_words = re.sub(\"[^a-zA-Z']\",\" \", mdg).lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our text as our, by now normal, list of words, we need to prepare it for use by the `NLTK` as a text. The command to do this is frighteningly straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdg_text = nltk.Text(mdg_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our text as, well, a text -- but, better, because `nltk.Text`? -- we can do some pretty amazing things, like develop in what linguists call a *key word in context (KWiC)* concordance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myword = mdg_text.concordance(\"dangerous\")\n",
    "print(myword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make this easier to manipulate if we move things around a bit, and then you can try searching for a few words yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try any of the following: hunt, hunted, hunter, dark, jungle\n",
    "myword = \"jungle\"\n",
    "print(mdg_text.concordance(myword))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will examine more ways to understand the relationship between individual words and the text as their context in a moment, but while we have our text as an object and we have a cluster of words in front of us, it might be useful to demonstrate the utility of being able to see where words occur in a text using the NLTK's dispersion plot functon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdg_text.dispersion_plot([\"hunter\", \"jungle\", \"dark\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you noticed that what you are doing above is feeding the `dispersion_plot()` function a list of words, you are beginning to get the hang of reading code, which means we can break out list out separately and then simply feed the name of the list to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [\"hunted\", \"hunter\", \"hunt\"]\n",
    "mdg_text.dispersion_plot(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the functions for examining words within a text have pretty straightforward names. Let's take a look at a number of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myword = \"hounds\"\n",
    "print(mdg_text.similar(myword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_contexts allows you to see where two words are used similarly:\n",
    "mdg_text.common_contexts([\"hounds\", \"hunter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please note that the collocations function uses the NLTK's stopwords list\n",
    "# in the background. I am not yet sure how to feed it a custom stopword list.\n",
    "mdg_text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a pretty straightforward function, but useful if you don't feel\n",
    "# like consulting your usually much larger word frequency list.\n",
    "mdg_text.count(\"dangerous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdg_text.concordance(\"dangerous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does \"dangerous\" occur within the larger text?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
