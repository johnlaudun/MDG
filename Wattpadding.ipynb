{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wattpadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re, os, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `wgetting` the HTML\n",
    "\n",
    "The first thing we need to do is get the html from which we will extract the texts we want. The easiest way I know to do that is to use `wget`. While we can use some command line apps from within a Jupyter notebook by simply prepending a percent sign, %, it does not appear that `wget` is one of those. I tried and got: `UsageError: Line magic function `%wget` not found.` \n",
    "\n",
    "So I opened a terminal window and ran `wget -w 2 -i ../inputs/wattpad_list.txt` from within the folder/directory where I wanted to have the files downloaded, a directory I created for this project called, of all things, `wattpad`. \n",
    "\n",
    "This initial usage did not go as planned: for every file in the list, a 403 error was returned. I wasn't sure if the cause was the Wattpad site wanting a login, so I pasted one of the URLs into a browser to see what I would get, and it returned the page. I then remembered something about some sites wanting a human-operated browser, so I looked up a way to tell a site that wget was a browser, which uses the `--user-agent` flag. The solution I settled on was from [AskApache][] and it consisted of editing, or in my case creating, a .wgetrc file which supplied the necessary information to the picky server:\n",
    "\n",
    "```bash\n",
    "### Sample Wget initialization file .wgetrc by https://www.askapache.com\n",
    "## Local settings (for a user to set in his $HOME/.wgetrc).  It is\n",
    "## *highly* undesirable to put these settings in the global file, since\n",
    "## they are potentially dangerous to \"normal\" users.\n",
    "##\n",
    "## Even when setting up your own ~/.wgetrc, you should know what you\n",
    "## are doing before doing so.\n",
    "header = Accept-Language: en-us,en;q=0.5\n",
    "header = Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\n",
    "header = Connection: keep-alive\n",
    "user_agent = Mozilla/5.0 (Windows NT 5.1; rv:10.0.2) Gecko/20100101 Firefox/10.0.2\n",
    "referer = https://www.askapache.com/\n",
    "robots = off\n",
    "```\n",
    "\n",
    "I logged out and back into the terminal to make sure the resource file got loaded, or whatever, and ran `wget` again. A whole lot of scrolling later and:\n",
    "\n",
    "```\n",
    "FINISHED --2019-08-30 19:13:23--\n",
    "Total wall clock time: 1m 47s\n",
    "Downloaded: 35 files, 3.8M in 0.8s (4.62 MB/s)\n",
    "```\n",
    "\n",
    "The short version of how to use `wget` can be found on a [post][] I wrote a few years ago.\n",
    "\n",
    "[AskApache]: https://www.askapache.com/linux/wget-header-trick/\n",
    "[post]: http://johnlaudun.org/20160518-wgetting-ted-talk-transcripts/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing with `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each page, we will want to get the title of the page and, while we're at it, we might as well pick up some of the metadata the site offers us about the page as well as the text on the page. We'll start with the text because it's all inside paragraph elements and we can probably navigate that fairly quickly.\n",
    "\n",
    "We will first create the particular kind of Python object that `BeautifulSoup` creates and which I kinda understand but not enought to explain it to anyone. (Note all the imports for this work are at the top of the page.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open(\"wattpad/279794502-my-immortal-commentary-chapters-1-5\"), \n",
    "                        \"html5lib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Text\n",
    "\n",
    "If we can simply get all elements with `data-p-id` in a page, I think we'll have all the content we need, so I am going to start with this:\n",
    "\n",
    "```html\n",
    "<p data-p-id=\"ad1ea648c5d5d7a6914ef1cf3afc9adc\">AN: Fangz 2 bloodytearz666 4 helpin me wif da chapta! BTW preps stop flaming ma story ok!<span class=\"comment-marker on-inline-comments-modal\">\n",
    "  <span class=\"num-comment\">\n",
    "    4\n",
    "  </span>\n",
    "  <span class=\"fa fa-comment-count fa-wp-neutral-2 \" aria-hidden=\"true\" style=\"font-size:28px;\"></span>\n",
    "</span>\n",
    "</p>\n",
    "```\n",
    "Otherwise, we will have to deal with the `div` that holds all these paragraphs and/or the `pre` tag -- which still may work.\n",
    "```html\n",
    "<div class=\"col-xs-10 col-xs-offset-1 col-sm-10 col-sm-offset-1 col-md-7 col-md-offset-1 col-lg-6 col-lg-offset-3 panel panel-reading\" dir=\"ltr\">\n",
    "<pre><p data-p-id=\"ad1ea648c5d5d7a6914ef1cf3afc9adc\">AN: Fangz 2 bloodytearz666 4 helpin me wif da chapta! BTW preps stop flaming ma story ok!<span class=\"comment-marker on-inline-comments-modal\">\n",
    "  <span class=\"num-comment\">\n",
    "    4\n",
    "  </span>\n",
    "  <span class=\"fa fa-comment-count fa-wp-neutral-2 \" aria-hidden=\"true\" style=\"font-size:28px;\"></span>\n",
    "</span>\n",
    "</p>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little experimentation turned up this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1.\n",
      "AN: Special fangz (get it, coz Im goffik) No. 2 my gf (ew not in that way) raven, I spy with my little eye a homophobe. bloodytearz666 4 helpin me wif da story and spelling. U rok! Justin ur da luv of my deprzzing life u rok 2! MCR ROX!\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Hate to break it to ya honey, but that's not how you separate chapters and ANs.\n",
      "Hi my name is Ebony Dark'ness Dementia Raven Way and I have long ebony black hair Redundancy much? (that's how I got my name) with purple streaks and red tips that reaches my mid-back and icy blue eyes like limpid tears and a lot of people tell me I look like Amy Lee (AN: if u don't know who she is get da hell out of here!). I'm not related to Gerard Way but I wish I was because he's a major fucking hottie. I don't even know where to begin on that last sentence. I'm a vampire but my teeth are straight and white. Stop fucking lyin'.. I have pale white skin. I'm also a witch, and I go to a magic school called Hogwarts in England HOGWARTS IS IN SCOTLAND where I'm in the seventh year (I'm seventeen). I'm a goth (in case you couldn't tell) and I wear mostly black. Wow, really? I love Hot Topic and I buy all my clothes from there. For example today I was wearing a black corset with matching lace around it and a black leather miniskirt, pink fishnets and black combat boots. I was wearing Nobody gives a shit. black lipstick, white foundation, black eyeliner and red eye shadow. I was walking outside Hogwarts. It was snowing and raining Hailing or sleeting, basically. Get your ass back inside. so there was no sun, which I was very happy about. A lot of preps stared at me. I put up my middle finger at them.\n",
      "\"Hey Ebony!\" shouted a voice. I looked up. It was.... Draco Malfoy! Why the elipse?\n",
      "\"What's up Draco?\" I asked.\n",
      "\"Nothing.\" he said shyly.\n",
      "But then, I heard my friends call me and I had to go away.\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX No.\n",
      "AN: IS it good? PLZ tell me fangz! This fic is one of those things that's so shitty that it's good.\n",
      "Chapter 2.\n",
      "AN: Fangz 2 bloodytearz666 4 helpin me wif da chapta! BTW preps stop flaming ma story ok!\n",
      "XXXXXXXXXXXXXXXXXXXXXX666XXXXXXXXXXXXXXXXXXXXXXXX\n",
      "The next day I woke up in my bedroom. It was snowing and raining again. I opened the door of my coffin and drank some blood from a bottle I had. My coffin was black ebony and inside it was hot pink velvet Later in the story though, Enoby claims she hates pink. with black lace on the ends. I got out of my coffin and took of my giant MCR t-shirt which I used for pajamas. Instead, I put on a black leather dress, a pentagram necklace, combat boots and black fishnets on. I put on four pairs of earrings in my pierced ears, and put my hair in a kind of messy bun. In a kind of messy bun.\n",
      "My friend, Willow (AN: Raven dis is u!) woke up then and grinned at me. She flipped her long waist-length raven black hair with pink streaks and opened her forest-green eyes. She put on her Marilyn Manson t-shirt with a black mini, fishnets and pointy high-heeled boots. We put on our makeup (black lipstick white foundation and black eyeliner.) Please stop describing clothes so damn much.\n",
      "\"OMFG, I saw you talking to Draco Malfoy yesterday!\" she said excitedly.\n",
      "\"Yeah? So?\" I said, blushing.\n",
      "\"Do you like Draco?\" she asked as we went out of the Slytherin common room and into the Great Hall.\n",
      "\"No I so fucking don't!\" I shouted. Which means you do. Come one Enoby, we read enough fics to know.\n"
     ]
    }
   ],
   "source": [
    "for item in soup.find_all('p'):\n",
    "#     print(item)\n",
    "    if item.has_attr('data-p-id'):\n",
    "        print(item.text) # Sadly, .text removes the bold and italic tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Title and the Metadata\n",
    "\n",
    "You can take a look at what the raw HTML looks like for yourself. The HTML below has been edited to focus on the elements and attributes we need to think about to get out the information we want: \n",
    "\n",
    "```html\n",
    "<header class=\"panel panel-reading text-center\">\n",
    "<h2>Chapter 2.\n",
    "</h2>\n",
    "<div class=\"story-stats\">\n",
    "<span class=\"reads\">\n",
    "899\n",
    "</span>\n",
    "<span class=\"votes\">\n",
    "45\n",
    "</span>\n",
    "<span class=\"comments on-comments\">\n",
    "<a href=\"#\">103</a>\n",
    "</span>\n",
    "</div>\n",
    "<div class=\"author hidden-lg\">\n",
    "<a class=\"on-navigate\" href=\"/user/VioletKingston\">VioletKingston</a>\n",
    "</div>\n",
    "</header>\n",
    "```\n",
    "\n",
    "The tree structure for this would look like:\n",
    "\n",
    "```\n",
    "body - header - h2\n",
    "              \\\n",
    "                story-stats - reads\n",
    "                            \\\n",
    "                              votes\n",
    "                             \\\n",
    "                              comments\n",
    "              \\ author\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title was easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapters 1-5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title = soup.find('h2')\n",
    "print(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can pick up the other metadata, starting with the number of times a text has been read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"reads\">\n",
      "<span aria-hidden=\"true\" class=\"fa fa-view fa-wp-neutral-2\" style=\"font-size:14px;\"></span> 17\n",
      "</span>]\n"
     ]
    }
   ],
   "source": [
    "reads = soup.select('span[class*=\"reads\"]')\n",
    "print(reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugly, and I can't get `BeautifulSoup` to clean this up, so I am going to go with some old-fashioned regex. The regex alone leaves in some newlines, for now, the ugliness below will have to do -- a better regex filter would take care of the newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our regex \"filter\"\n",
    "clean = re.compile('<.*?>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# Our filtering process\n",
    "text = re.sub(clean, '', str(reads)[1:-1]).rstrip().lstrip()\n",
    "print(text) # Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0\n"
     ]
    }
   ],
   "source": [
    "votes = re.sub(clean, '', str(soup.select('span[class*=\"votes\"]'))).lstrip('[\\n').rstrip('\\n]')\n",
    "print(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "comments = re.sub(clean, '', str(soup.select('span[class*=\"comments\"]'))).lstrip('[\\n').rstrip('\\n]')\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite done. We still need author, and in looking at the HTML for where the author is, I see that what I have as title above is probably more like a subtitle or part. Here's the relevant code from the HTML file:\n",
    "```html\n",
    "<h1 class=\"title h5\">\n",
    "My Immortal Commentary\n",
    "</h1>\n",
    "<span class=\"author h6\">by jyushiimatsuno</span>\n",
    "</span>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jyushiimatsuno\n"
     ]
    }
   ],
   "source": [
    "author = re.sub(clean, '', str(soup.select('span[class*=\"author h6\"]'))).lstrip('[\\n by').rstrip('\\n]')\n",
    "print(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Immortal Commentary\n"
     ]
    }
   ],
   "source": [
    "title = re.sub(clean, '', str(soup.select('h1[class*=\"title h5\"]'))).lstrip('[\\n').rstrip('\\n]')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now to stitch these various pieces of working, if also ugly, code together. We are going to create a function that produces these results. We are then going to write a `for` loop that works through all the files in our `inputs` directory, runs them through our function, and then we are going to save the outputs to a `csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(soup):\n",
    "    # This function requires re\n",
    "    clean = re.compile('<.*?>')\n",
    "    title = re.sub(clean, '', str(soup.select('h1[class*=\"title h5\"]'))).lstrip('[\\n').rstrip('\\n]')\n",
    "    subtitle = soup.find('h2').text.rstrip()\n",
    "    author = re.sub(clean, '', str(soup.select('span[class*=\"author h6\"]'))).lstrip('[\\n by').rstrip('\\n]')\n",
    "    reads = re.sub(clean, '', str(soup.select('span[class*=\"reads\"]'))).lstrip('[\\n ').rstrip('\\n]')\n",
    "    votes = re.sub(clean, '', str(soup.select('span[class*=\"votes\"]'))).lstrip('[\\n ').rstrip('\\n]')\n",
    "    comments = re.sub(clean, '', str(soup.select('span[class*=\"comments\"]'))).lstrip('[\\n').rstrip('\\n]')\n",
    "    text = ''.join([item.text for item in soup.find_all('p') if item.has_attr('data-p-id')])\n",
    "    return(title, subtitle, author, reads, votes, comments, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the functionality of the parse feature on our currently loaded soup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Immortal Commentary\n",
      "Chapters 1-5\n",
      "jyushiimatsuno\n",
      "17\n",
      "0\n",
      "2\n",
      "Chapter 1.AN: Special fangz (get it, coz Im goffik) No. 2 my gf (ew not in that way) raven, I spy with my little eye a homophobe. bloodytearz666 4 helpin me wif da story and spelling. U rok! Justin ur da luv of my deprzzing life u rok 2! MCR ROX!XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Hate to break it to ya honey, but that's not how you separate chapters and ANs.Hi my name is Ebony Dark'ness Dementia Raven Way and I have long ebony black hair Redundancy much? (that's how I got my name) with purple streaks and red tips that reaches my mid-back and icy blue eyes like limpid tears and a lot of people tell me I look like Amy Lee (AN: if u don't know who she is get da hell out of here!). I'm not related to Gerard Way but I wish I was because he's a major fucking hottie. I don't even know where to begin on that last sentence. I'm a vampire but my teeth are straight and white. Stop fucking lyin'.. I have pale white skin. I'm also a witch, and I go to a magic school called Hogwarts in England HOGWARTS IS IN SCOTLAND where I'm in the seventh year (I'm seventeen). I'm a goth (in case you couldn't tell) and I wear mostly black. Wow, really? I love Hot Topic and I buy all my clothes from there. For example today I was wearing a black corset with matching lace around it and a black leather miniskirt, pink fishnets and black combat boots. I was wearing Nobody gives a shit. black lipstick, white foundation, black eyeliner and red eye shadow. I was walking outside Hogwarts. It was snowing and raining Hailing or sleeting, basically. Get your ass back inside. so there was no sun, which I was very happy about. A lot of preps stared at me. I put up my middle finger at them.\"Hey Ebony!\" shouted a voice. I looked up. It was.... Draco Malfoy! Why the elipse?\"What's up Draco?\" I asked.\"Nothing.\" he said shyly.But then, I heard my friends call me and I had to go away.XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX No.AN: IS it good? PLZ tell me fangz! This fic is one of those things that's so shitty that it's good.Chapter 2.AN: Fangz 2 bloodytearz666 4 helpin me wif da chapta! BTW preps stop flaming ma story ok!XXXXXXXXXXXXXXXXXXXXXX666XXXXXXXXXXXXXXXXXXXXXXXXThe next day I woke up in my bedroom. It was snowing and raining again. I opened the door of my coffin and drank some blood from a bottle I had. My coffin was black ebony and inside it was hot pink velvet Later in the story though, Enoby claims she hates pink. with black lace on the ends. I got out of my coffin and took of my giant MCR t-shirt which I used for pajamas. Instead, I put on a black leather dress, a pentagram necklace, combat boots and black fishnets on. I put on four pairs of earrings in my pierced ears, and put my hair in a kind of messy bun. In a kind of messy bun.My friend, Willow (AN: Raven dis is u!) woke up then and grinned at me. She flipped her long waist-length raven black hair with pink streaks and opened her forest-green eyes. She put on her Marilyn Manson t-shirt with a black mini, fishnets and pointy high-heeled boots. We put on our makeup (black lipstick white foundation and black eyeliner.) Please stop describing clothes so damn much.\"OMFG, I saw you talking to Draco Malfoy yesterday!\" she said excitedly.\"Yeah? So?\" I said, blushing.\"Do you like Draco?\" she asked as we went out of the Slytherin common room and into the Great Hall.\"No I so fucking don't!\" I shouted. Which means you do. Come one Enoby, we read enough fics to know.\n"
     ]
    }
   ],
   "source": [
    "for item in parse(soup):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below for saving results of a parsing operation to a `csv` files is drawn from some boilerplate I have lying around that was first developed by Padraic C on StackOverflow. (All hail, Padraic!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(pth, out):\n",
    "    \"\"\"This function requires both the csv and os modules.\"\"\"\n",
    "    # open file to write to.\n",
    "    with open(out, \"w\") as out:\n",
    "        # create csv.writer. \n",
    "        wr = csv.writer(out)\n",
    "        # write our headers.\n",
    "        wr.writerow([\"title\", \"subtitle\", \"author\", \"reads\", \"votes\", \"comments\", \"text\"])\n",
    "        # get all our html files.\n",
    "        for html in os.listdir(pth):\n",
    "            with open(os.path.join(pth, html)) as f:\n",
    "                # parse the file and write the data to a row.\n",
    "                wr.writerow(parse(BeautifulSoup(f, \"html5lib\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then all you do it this to run everything -- make sure you know what directory you are in before doing this so that the the function has the correct path to the input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(\"./wattpad\",\"./outputs/beloveds.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
