{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to understand the context of a word? Can we get the words that surround a word in a text and do something with them?\n",
    "\n",
    "```python\n",
    "for word in text:\n",
    "    get the values of the X words before the target_word\n",
    "    get the values of the X words after the target_word\n",
    "    sum the values (?)\n",
    "    return sum for each instance of word \n",
    "```\n",
    "\n",
    "I am going to re-use some of the code from Gina's `word.py` script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I am working in Jupyter notebook, I tend to migrate my import toward the top of the notebook so that should I export to a standalone script, the imports are already where they should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# INPUTS\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "filename = \"texts/mdg.txt\"\n",
    "target = \"game\"\n",
    "window = 5\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# For added stopwords:\n",
    "# newStopWords = ['stopWord1','stopWord2'] # This could be a file\n",
    "# stopwords.extend(newStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['right', 'somewhere', 'large', 'island', 'said', 'whitney', 'rather', 'mystery', 'island', 'rainsford', 'asked', 'old', 'charts', 'call', \"'ship\", 'trap', 'island', \"'\", 'whitney', 'replied', 'suggestive', 'name', 'sailors', 'curious', 'dread', 'place', 'know', 'superstition', \"can't\", 'see', 'remarked', 'rainsford', 'trying', 'peer', 'dank', 'tropical', 'night', 'palpable', 'pressed', 'thick']\n"
     ]
    }
   ],
   "source": [
    "# Load the file \n",
    "with open(filename, 'r') as myfile:\n",
    "    text = myfile.read()\n",
    "# convert it to a list of words \n",
    "normalized_words = re.sub(\"[^a-zA-Z']\",\" \", text).lower().split()\n",
    "# drop unwanted words\n",
    "words = [word for word in normalized_words if not word in stop_words]\n",
    "\n",
    "# Test how things are going:\n",
    "print(words[0:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `enumerate` function is really useful: it takes a list and creates a list of pairs with a number associated with the position for each item in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 this\n",
      "1 is\n",
      "2 a\n",
      "3 sentence\n"
     ]
    }
   ],
   "source": [
    "string = \"This is a sentence.\"\n",
    "words = re.sub(\"[^a-zA-Z']\",\" \", string).lower().split()\n",
    "numbered = enumerate(words)\n",
    "for i, j in numbered:\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you cannot simply `print(numbered)` as this will only return `<enumerate object at 0x12105fe`. You will encounter this particular phenomenon in a number of instances in Python. It simply means you have created a kind of object that cannot be printed in its current form: you will need to iterate over it. And whenever you hear the word *iterate* you should almost always think `for`, and that is what we have done above. Since we know that `enumerate` produces pairs of objects, we feed the for loop a pair of iterators -- here I've used `i` and `j` but you could use anything that makes sense and helps make your code more readable and usable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110, 1360, 1377, 1387, 1392, 1454, 1550, 2165, 2196, 2212, 2664, 3931, 3993]\n",
      "['game', 'game', 'game', 'game', 'game', 'game', 'game', 'game', 'game', 'game', 'game', 'game', 'game']\n"
     ]
    }
   ],
   "source": [
    "targetIndices = [i for i, x in enumerate(words) if x == target]\n",
    "\n",
    "# Let's see those locations\n",
    "print(targetIndices)\n",
    "\n",
    "# Now let's make sure that the word associated with those locations is ours:\n",
    "print([words[i] for i in targetIndices])\n",
    "\n",
    "# To get the single line above, I first wrote this:\n",
    "# for i in targetIndices:\n",
    "#     print (words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = []\n",
    "after = []\n",
    "for index, word in enumerate(words):\n",
    "    for i in targetIndices:\n",
    "        if index >= (i - window) and index < i:\n",
    "            before.append(word)\n",
    "        if index > i and index <= (i + window):\n",
    "            after.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rot', 'whitney', 'said', 'rainsford', 'big', 'ord', 'cape', 'buffalo', 'dangerous', 'big', 'sir', 'cape', 'buffalo', 'dangerous', 'big', 'said', 'slow', 'tone', 'hunt', 'dangerous', 'game', 'rainsford', 'expressed', 'surprise', 'big', 'said', 'general', 'shall', 'glad', 'society', 'always', 'hunt', 'hunted', 'every', 'kind', 'rainsford', 'effort', 'held', 'tongue', 'check', 'eludes', 'three', 'whole', 'days', 'wins', 'give', 'option', 'course', 'need', 'play', 'glass', 'rainsford', 'sat', 'staring', 'find', 'quarry', 'escaped', 'course', 'american', 'played', 'sucked', 'breath', 'smiled', 'congratulate', 'said']\n"
     ]
    }
   ],
   "source": [
    "print(before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think what I want below is a function that will take an index for a word and then return the words before and the words after: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windoWord (text):\n",
    "    before = []\n",
    "    after = []\n",
    "    for index, word in enumerate(words):\n",
    "        for i in targetIndices:\n",
    "            if index >= (i - window) and index < i:\n",
    "                before.append(word)\n",
    "            if index > i and index <= (i + window):\n",
    "                after.append(word)\n",
    "    return before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(targetIndices)):\n",
    "    if i <= len(before)/window:\n",
    "        print(\" \".join(before[i*window:(i+1)*window]) + \"\\n\")\n",
    "\n",
    "for i in range(len(targetIndices)):\n",
    "    if i <= len(after)/window:\n",
    "        print(\" \".join(after[i*window:(i+1)*window]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
