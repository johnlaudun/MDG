{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Doing Things with Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a name=\"toc\"></a>\n",
    "\n",
    "**[Loading a File & Understanding What It Is](#file)**  \n",
    "**[Tokenizing](#tokenizing)**  \n",
    "[A Quick Note about Normalization](#norm)  \n",
    "[Using regex to Tokenize](#REtoke)   \n",
    "[Using NLTK Tokenizers](#nltktoken)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first line of code run _here_ is something internal to Jupyter Notebooks that allows us to place any graphical output into the page itself and not in a separate window or file. (We can still save output to a file, if we want.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "figsize(12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a File & Understanding What It Is <a name=\"file\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# The work of the two lines above can also be achieved in one line.\n",
    "# See if your growing Pythonista abilities can't tell how this is done!\n",
    "mdg = open('texts/mdg.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the regular expression library\n",
    "import re\n",
    "\n",
    "mdg_words = re.sub(\"[^a-zA-Z']\",\" \", mdg).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this instance, we are going to tell Python that we only want \n",
    "# one particular tool from the larger toolkit:\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdg_tokens = WhitespaceTokenizer().tokenize(mdg.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What would happen if we were to read the text differently, if we were to read all the words, but this time with the words in alphabetical order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(mdg_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What's this? That's a lot of *a*s and *about*s. What happens if we look at just the words without repetition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(set(mdg_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That looks like a lot of words. If we ask how many by counting how long the set of words is, we get: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how I enclose the text I want to print in single quotes\n",
    "# so that I can use double quotes in the text itself:\n",
    "print('There are {} words in \"The Most Dangerous Game.\"'.format(len(set(mdg_tokens))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Tokenizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist()\n",
    "for sentence in nltk.tokenize.sent_tokenize(mdg):\n",
    "    for word in nltk.tokenize.word_tokenize(sentence):\n",
    "        fdist[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fdist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.tokenize.sent_tokenize(mdg)\n",
    "# print(sentence for sentence in sentences[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.tokenize.word_tokenize(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From our experiments above we learn that approximately two thousand words are spread out over 8000 places. If averaged over the entire text, each word appears 4 times, but looking over our sorted `mdg_words` above, we can see that the word **and** appears 162 times alone. And it's not even the top 5 of most used words! \n",
    "\n",
    "In order they are:\n",
    "\n",
    "    the, 512\n",
    "    a, 258\n",
    "    he, 248\n",
    "    i, 177\n",
    "    of, 172\n",
    "    and, 164\n",
    "\n",
    "The list above is the start of a word frequency list. There are a number of ways to do this, and I will include those in separate files for your reference, but since we have started with the NLTK, I thought we would stay with it. We have a choice to make, however: we can either continue to import one tool at a time from the NLTK library, or we can just say to ourselves that we're going to be playing with a lot of the tools, so why not just bring them all into our workspace?\n",
    "\n",
    "Please note that once I've imported all of the `nltk` library, I need to tell Python that a particular tool, or function, comes from that library. Sometimes functions from two different, and large, libraries can have the same name, prepending the library name is one way that Python has of avoiding what are called \"namespace conflicts,\" which is a fancy way of saying you can't call two things by the same name. You've seen both ways of doing things now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist = nltk.FreqDist(mdg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(freq_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, frequency in freq_dist.most_common(10):\n",
    "    print('{}:  {}'.format(word, frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, frequency in freq_dist:\n",
    "    print(word, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdg_dict = {key:value for word, frequency in freq_dist.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Let's graph the 50 most frequent words:\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "# This shows all the words: still working on slices\n",
    "freq_dist.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Save these results to a CSV file (makes it easier for the Excel-impaired)\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "mdg_counts.to_csv('../data/mdg_word_freq.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = dict()\n",
    "for size in 2, 3, 4, 5:\n",
    "    all_counts[size] = nltk.FreqDist(nltk.ngrams(mdg_words, size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts[5].most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.style.use('ggplot')\n",
    "ax = df[['Word','Frequency']].plot(kind='bar', \n",
    "                                   title =\"Frequency of Words in MDG\",\n",
    "                                   figsize=(20,10),\n",
    "                                   legend=True)\n",
    "ax.set_xlabel(\"Word\")\n",
    "ax.set_ylabel(\"Occurrences\")\n",
    "ax.set_xticklabels(list(df['Word'])) \n",
    "mpl.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myword = mdg_words.concordance(\"dangerous\")\n",
    "print(myword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.similar(\"love\")\n",
    "text.common_contexts([\"husband\", \"wife\"])\n",
    "text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical Diversity of MDG:\n",
    "len(mdg2_word_list) / len(set(mdg2_word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mdg_tokens) / len(set(mdg_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, a word occurs four times in \"The Most Dangerous Game.\"\n",
    "\n",
    "Out of curiosity, how many words occur four times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfrequency = nltk.FreqDist(mdg_tokens)\n",
    "four_times = [word for word in wordfrequency.keys() if wordfrequency[word] == 4]\n",
    "print(four_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdg_text.count(\"dangerous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdg_text.concordance(\"dangerous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does \"dangerous\" occur within the larger text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdg_text.dispersion_plot([\"dangerous\", \"danger\", \"game\", \"fear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfrequency.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
