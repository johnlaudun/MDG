{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../corpora/legends/louisiana') as fp:\n",
    "    for file in fp:\n",
    "\n",
    "    lines = f.readlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {  'a' : \"Mr. Green killed Colonel Mustard in the study with the candlestick. \\\n",
    "    Mr. Green is not a very nice fellow.\", \n",
    "            'b' : \"Professor Plum has a green plant in his study.\", \n",
    "            'c' : \"Miss Scarlett watered Professor Plum's green plant while he was \\\n",
    "                away from his office last week.\"}\n",
    "                \n",
    "terms = { 'a' : [ i.lower() for i in corpus['a'].split() ], \n",
    "          'b' : [ i.lower() for i in corpus['b'].split() ], \n",
    "          'c' : [ i.lower() for i in corpus['c'].split() ] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mr.', 'green', 'killed', 'colonel', 'mustard', 'in', 'the', 'study', 'with', 'the', 'candlestick.', 'mr.', 'green', 'is', 'not', 'a', 'very', 'nice', 'fellow.']\n"
     ]
    }
   ],
   "source": [
    "print(terms[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a : Mr. Green killed Colonel Mustard in the study with the candlestick. Mr. Green is not a very nice fellow.\n",
      "b : Professor Plum has a green plant in his study.\n",
      "c : Miss Scarlett watered Professor Plum's green plant while he was away from his office last week.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "# Enter in a query term from the corpus variable\n",
    "QUERY_TERMS = ['mr.', 'green']\n",
    "\n",
    "def tf(term, doc, normalize=True):\n",
    "    doc = doc.lower().split()\n",
    "    if normalize:\n",
    "        return doc.count(term.lower()) / float(len(doc))\n",
    "    else:\n",
    "        return doc.count(term.lower()) / 1.0\n",
    "\n",
    "\n",
    "def idf(term, corpus):\n",
    "    num_texts_with_term = len([True for text in corpus if term.lower()\n",
    "                              in text.lower().split()])\n",
    "\n",
    "    # tf-idf calc involves multiplying against a tf value less than 0, so it's\n",
    "    # necessary to return a value greater than 1 for consistent scoring.\n",
    "    # (Multiplying two values less than 1 returns a value less than each of\n",
    "    # them.)\n",
    "\n",
    "    try:\n",
    "        return 1.0 + log(float(len(corpus)) / num_texts_with_term)\n",
    "    except ZeroDivisionError:\n",
    "        return 1.0\n",
    "\n",
    "\n",
    "def tf_idf(term, doc, corpus):\n",
    "    return tf(term, doc) * idf(term, corpus)\n",
    "\n",
    "\n",
    "corpus = \\\n",
    "    {'a': 'Mr. Green killed Colonel Mustard in the study with the candlestick. \\\n",
    "Mr. Green is not a very nice fellow.',\n",
    "     'b': 'Professor Plum has a green plant in his study.',\n",
    "     'c': \"Miss Scarlett watered Professor Plum's green plant while he was away \\\n",
    "from his office last week.\"}\n",
    "\n",
    "for (k, v) in sorted(corpus.items()):\n",
    "    print(k, ':', v)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF(a): mr. 0.10526315789473684\n",
      "TF(b): mr. 0.0\n",
      "TF(c): mr. 0.0\n",
      "IDF: mr. 2.09861228866811\n",
      "\n",
      "TF-IDF(a): mr. 0.22090655670190631\n",
      "TF-IDF(b): mr. 0.0\n",
      "TF-IDF(c): mr. 0.0\n",
      "\n",
      "TF(a): green 0.10526315789473684\n",
      "TF(b): green 0.1111111111111111\n",
      "TF(c): green 0.0625\n",
      "IDF: green 1.0\n",
      "\n",
      "TF-IDF(a): green 0.10526315789473684\n",
      "TF-IDF(b): green 0.1111111111111111\n",
      "TF-IDF(c): green 0.0625\n",
      "\n",
      "Overall TF-IDF scores for query 'mr. green'\n",
      "a 0.3261697145966431\n",
      "b 0.1111111111111111\n",
      "c 0.0625\n"
     ]
    }
   ],
   "source": [
    "# Score queries by calculating cumulative tf_idf score for each term in query\n",
    "\n",
    "query_scores = {'a': 0, 'b': 0, 'c': 0}\n",
    "for term in [t.lower() for t in QUERY_TERMS]:\n",
    "    for doc in sorted(corpus):\n",
    "        print('TF({0}): {1}'.format(doc, term), tf(term, corpus[doc]))\n",
    "    print('IDF: {0}'.format(term), idf(term, corpus.values()))\n",
    "    print()\n",
    "\n",
    "    for doc in sorted(corpus):\n",
    "        score = tf_idf(term, corpus[doc], corpus.values())\n",
    "        print('TF-IDF({0}): {1}'.format(doc, term), score)\n",
    "        query_scores[doc] += score\n",
    "    print()\n",
    "\n",
    "print(\"Overall TF-IDF scores for query '{0}'\".format(' '.join(QUERY_TERMS)))\n",
    "for (doc, score) in sorted(query_scores.items()):\n",
    "    print(doc, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.cluster\n",
    "\n",
    "# Load in human language data from wherever you've saved it\n",
    "DATA = 'resources/ch05-textfiles/ch05-timoreilly.json'\n",
    "data = json.loads(open(DATA).read())\n",
    "\n",
    "all_posts = [ (i['title'] + \" \" + i['content']).lower().split() for i in data ]\n",
    "\n",
    "# Provides tf, idf, and tf_idf abstractions for scoring\n",
    "\n",
    "tc = nltk.TextCollection(all_posts)\n",
    "\n",
    "# Compute a term-document matrix such that td_matrix[doc_title][term]\n",
    "# returns a tf-idf score for the term in the document\n",
    "\n",
    "td_matrix = {}\n",
    "for idx in range(len(all_posts)):\n",
    "    post = all_posts[idx]\n",
    "    fdist = nltk.FreqDist(post)\n",
    "\n",
    "    doc_title = data[idx]['title'].replace('\\n', '')\n",
    "    td_matrix[doc_title] = {}\n",
    "\n",
    "    for term in fdist.keys():\n",
    "        td_matrix[doc_title][term] = tc.tf_idf(term, post)\n",
    "\n",
    "# Build vectors such that term scores are in the same positions...\n",
    "\n",
    "distances = {}\n",
    "for title1 in td_matrix.keys():\n",
    "\n",
    "    distances[title1] = {}\n",
    "    (min_dist, most_similar) = (1.0, ('', ''))\n",
    "\n",
    "    for title2 in td_matrix.keys():\n",
    "\n",
    "        # Take care not to mutate the original data structures\n",
    "        # since we're in a loop and need the originals multiple times\n",
    "\n",
    "        terms1 = td_matrix[title1].copy()\n",
    "        terms2 = td_matrix[title2].copy()\n",
    "\n",
    "        # Fill in \"gaps\" in each map so vectors of the same length can be computed\n",
    "        for term1 in terms1:\n",
    "            if term1 not in terms2:\n",
    "                terms2[term1] = 0\n",
    "\n",
    "        for term2 in terms2:\n",
    "            if term2 not in terms1:\n",
    "                terms1[term2] = 0\n",
    "\n",
    "        # Create vectors from term maps\n",
    "        v1 = [score for (term, score) in sorted(terms1.items())]\n",
    "        v2 = [score for (term, score) in sorted(terms2.items())]\n",
    "\n",
    "        # Compute similarity amongst documents\n",
    "        distances[title1][title2] = nltk.cluster.util.cosine_distance(v1, v2)\n",
    "\n",
    "        if title1 == title2:\n",
    "            #print distances[title1][title2]\n",
    "            continue\n",
    "\n",
    "        if distances[title1][title2] < min_dist:\n",
    "            (min_dist, most_similar) = (distances[title1][title2], title2)\n",
    "\n",
    "    print(u'Most similar (score: {})\\n{}\\n{}\\n'.format(1-min_dist, title1,most_similar))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14a02b88778d8fb8b6aeb4ad427a942bc53dfcda9d7e3737237788289e0d2d23"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dev': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}